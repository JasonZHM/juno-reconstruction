# JUNO 能量重建实验报告

**Team: PMTMender**

**Members: 刘明昊 沈若寒  赵海萌**

**小组主要分工：**

- 刘明昊：
- 沈若寒：性能优化
- 赵海萌：Ghost Hunter Legacy，撰写报告

**注意！** 本报告仅是一个简短的说明文档和操作手册，详细实现思路与细节请见`model.ipynb, train.ipynb, final.ipynb` 中的Markdown说明。

## 摘要

本项目以JUNO中微子探测装置为背景，试图通过物理分析、信号处理与机器学习等技术，从PMT波形中重建出中微子事件的能量。通过数据预处理、特征工程和多级LightGBM的统计学习，我们的算法能在很短的时间内，以很高的精度重构出事件的能量，同时具备很好的可解释性。高效率、高精度、可解释的能量重建手段有助于我们理解中微子质量顺序的难题。

## 目录

[TOC]

## 整体思路

我们面临的问题是要从波形中重构出事件能量。考虑到我们拥有大量的训练数据，这是一个典型的机器学习回归问题。其中的困难主要在于**特征工程**：即如何从波形中提取出有效的特征，用于训练预测能量的模型。

为了保证较高的效率、可复现性与可解释性，避免过大的计算资源需求，我们没有采取以BERT为首的一系列深度神经网络，而是采用了Kaggle等数据科学竞赛中常用的传统机器学习算法LightGBM，其具有**效率高、迭代快、效果好**的特点，方便我们进行调整并测试不同的特征工程方法与超参数。

那么余下的问题便是特征工程，如何从巨量数据的波形中提取出有效的特征。考虑到击中每个波形的PE个数是一个重要的中间量，我们首先将整个波形-能量的任务拆分成两步：波形-每个波形的PE个数和PE个数-能量。

对于这两个步骤，我们分别提取特征进行模型训练（具体特征工程见`model.ipynb`），最后合成成为多级LightGBM分步进行预测。

## 文件结构

本项目的文件结构如下：

```
|-- project-1-junosap-pmtmender
		|-- README.md
    |-- requirements.txt
    |-- Makefile
    |-- utils.py
    |-- waveform.py
    |-- train.ipynb
    |-- final.ipynb
    |-- model.ipynb
```

其中`README.md` 为本实验报告，`requirements.txt` 罗列了本项目的依赖包版本，`Makefile` 定义了处理流水线， `waveform.py` 进行数据预处理，`train.ipynb` 训练模型，`final.ipynb` 生成预测答案。

**注意**：`model.ipynb` 是一个简要的示例代码，阅读它可以使读者更好地了解我们的算法。

## 执行方式

在执行前请确保依赖包都已安装并符合版本要求，执行

```shell
pip install -r requirements.txt
```

以安装依赖包。

在项目目录下用 `shell` 执行代码

```shell
make
```

可以完整地执行整个项目的流程，下载训练集、预处理数据、训练模型、生成预测答案。

执行代码

```shell
make data
make train
make model
make ans
```

可分别下载数据、预处理数据、训练模型、生成预测答案。

执行代码

```shell
make clean
```

可以清理下载的数据集、预处理数据和训练模型，但不会清理预测答案。

若要单独执行预处理数据，可以执行

```shell
python3 waveform.py
```

若要单独预处理数据和训练模型，可以执行`train.ipynb`和`final.ipynb`。

## 优化方法

训练过程中的速度瓶颈主要在于手作算法``utils.getPePerWF``，最初在一个数据集上运行需要40分钟。根据我们在一阶段的经验，这里有相当大的优化空间。

#### Numpy并行化

最初的算法只能一个一个地处理波形，产生的大量的循环。我们的核心目的就是同时处理多个波形，来减少循环的数量。

对于一批次中的不同波形，它们可能具有非常不同的特征。比如，大部分的波形都只含有小于5个的PE，而少部分波形能含有大几十个的PE。如果我们以完全一样的方式来处理这些波形，就会造成大量的计算浪费。因此，即使我们同时处理它们，也需要在过程中动态地进行数据的舍去。

我们的解决方法是通过创建数组``label``来控制还有哪些波形需要计算。每次循环都会更新``label``，然后程序根据``label``留下还需要计算的数据，并通过``label``写入那些累积变量。这就要求``label``是一个``int``数组而非``bool``数组，因为它不仅需要表示一次循环中的舍去，还需要表达数据在最原始输入中的位置。

#### 多进程并行化

即使``numpy``化大大加快了速度，但程序只能使用单核。程序多为判断与求和，``numpy``中的这些函数没有多核优化，``numexpr``也难以加速。程序还是顺序无关的。因此，多进程就是合理又必要的加速手段。

我们将数据集先用``np.array_split``分割成小块，然后用``utils.getPePerWF``处理这些小块，最后将这些小块通过``np.concatenate``完成输出。

我们试图通过调节块数量以及进程数来进一步优化性能。结果发现块数量对性能没有明显影响；进程数大于4后每个核心的利用率就到不了$100\%$，说明内存性能开始成为瓶颈，但继续增加进程数性能却还有微小的提升。

最终，处理一个数据集仅需34s。

#### 多进程读取
由于hdf5文件在读取时需要解压缩，而这个解压缩只能单核运行，导致读取时无法充分利用硬盘。我们将文件分为小块并读取，虽然未能实现与进程数线性的提升，但依然提速了约50%。